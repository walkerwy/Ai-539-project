{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Running:\n",
    "Please Install all from the requirements.txt (pip install -r requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder_decoder_layers = 3\n",
    "encoder_decoder_heads = 8\n",
    "embedded_dim = 768 # Don't change\n",
    "max_length = 32\n",
    "coco_dataset_ratio = 50\n",
    "coco_dataset_dir = \"./coco\"\n",
    "vocab_size = 50257\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "patience = 3\n",
    "weight_decay = 1e-5\n",
    "preprocess_swin_model = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "encoder_model = \"microsoft/swin-base-patch4-window7-224-in22k\"\n",
    "decoder_model = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Format datasets\n",
    "This will take some time to finishing running the first time. It took me roughly 40 minutes.\n",
    "\n",
    "This section does the following actions:\n",
    "1. Downloads the Dataset\n",
    "2. Keeps images with only 3 or 4 dim\n",
    "3. Transforms the dataset \n",
    "4. Turns the data set into data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for HuggingFaceM4/COCO contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/HuggingFaceM4/COCO\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Map:   0%|          | 0/24920 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x360 at 0x1970BEC87D0>, 'filepath': 'COCO_val2014_000000391895.jpg', 'sentids': [770337, 771687, 772707, 776154, 781998], 'filename': 'COCO_val2014_000000391895.jpg', 'imgid': 0, 'split': 'test', 'sentences': {'tokens': ['a', 'man', 'with', 'a', 'red', 'helmet', 'on', 'a', 'small', 'moped', 'on', 'a', 'dirt', 'road'], 'raw': 'A man with a red helmet on a small moped on a dirt road. ', 'imgid': 0, 'sentid': 770337}, 'cocoid': 391895}\n",
      "A man with a red helmet on a small moped on a dirt road. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 48\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m: pixel_values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#for data in train_ds:\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#print (data)\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m test_dataset2 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dat \u001b[38;5;129;01min\u001b[39;00m test_dataset2:    \n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m (dat)\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    565\u001b[0m }\n\u001b[0;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3157\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3158\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3517\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3515\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3517\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3420\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[44], line 38\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     34\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer(items[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     35\u001b[0m                     max_length\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# tokenize captions\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m targets \u001b[38;5;241m=\u001b[39m tokenizer([\u001b[43msentence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m items[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     39\u001b[0m                     max_length\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Keep image file\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m: pixel_values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: targets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTImageProcessor, GPT2TokenizerFast, AutoImageProcessor, SwinModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Download the train, val and test splits of the COCO dataset\n",
    "train_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"train[:{coco_dataset_ratio}%]\", cache_dir=coco_dataset_dir)\n",
    "valid_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"validation[:{coco_dataset_ratio}%]\", cache_dir=coco_dataset_dir)\n",
    "test_ds = load_dataset(\"HuggingFaceM4/COCO\", split=\"test\", cache_dir=coco_dataset_dir)\n",
    "\n",
    "# Filter all non 3 or 4 dim images out\n",
    "# Can change num_proc, but might be errors with np\n",
    "train_ds = train_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=1)\n",
    "valid_ds = valid_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=1)\n",
    "test_ds = test_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=1)\n",
    "\n",
    "# Does pre processing on the data set\n",
    "# This includes pre-trained ViTimage feature extraction and tokenizing captions\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(decoder_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "image_processor = ViTImageProcessor.from_pretrained(encoder_model)\n",
    "image_processor_swin = SwinModel.from_pretrained(preprocess_swin_model)\n",
    "\n",
    "def preprocess(items):\n",
    "    # Image pre-processing\n",
    "    # use ViT and SWIN since no back prop\n",
    "    pixel_values = image_processor(items[\"image\"], return_tensors=\"pt\").pixel_values\n",
    "    with torch.no_grad():\n",
    "        pixel_values = image_processor_swin (pixel_values)\n",
    "\n",
    "    print (items)\n",
    "    print (items[\"sentences\"]['raw'])\n",
    "    tokens = tokenizer(items[\"sentences\"]['raw'],\n",
    "                        max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    print (tokens)\n",
    "\n",
    "    # tokenize captions\n",
    "    targets = tokenizer([sentence[\"raw\"] for sentence in items[\"sentences\"]],\n",
    "                        max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Keep image file\n",
    "\n",
    "    return {'pixel_values': pixel_values, 'labels': targets[\"input_ids\"]}\n",
    "\n",
    "#for data in train_ds:\n",
    "    #print (data)\n",
    "\n",
    "test_dataset2 = test_ds.map(preprocess)\n",
    "for dat in test_dataset2:    \n",
    "    print (dat)\n",
    "\n",
    "train_dataset = train_ds.with_transform(preprocess)\n",
    "valid_dataset = valid_ds.with_transform(preprocess)\n",
    "test_dataset = test_ds.with_transform(preprocess)\n",
    "\n",
    "\n",
    "# Turns the dataset into a torch DataLoader\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "train_dataset_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset_loader = DataLoader(valid_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)\n",
    "test_dataset_loader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "Creates the PureT model from the paper\n",
    "\n",
    "This section does the following actions:\n",
    "1. Creates the SWIN Transformer used by PureT\n",
    "2. Creates the PureT encoder\n",
    "3. Creates the PureT decoder\n",
    "4. Creates the PureT model\n",
    "\n",
    "Download the pre-trained SwinT weights from here https://drive.google.com/drive/folders/1HBw5NGGw8DjkyNurksCP5v8a5f0FG7zU and put them in this folder before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.models\n",
    "from transformers import SwinModel\n",
    "\n",
    "class BasicCaptionTransformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCaptionTransformer, self).__init__()\n",
    "\n",
    "        # Image processing pre-done with ViTImageProcessor in the Downloading and Format datasets step\n",
    "        self.swin = SwinModel.from_pretrained(preprocess_swin_model)\n",
    "\n",
    "        # build encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedded_dim, nhead=encoder_decoder_heads, batch_first=True)\n",
    "        self.encoders = nn.TransformerEncoder(encoder_layer, encoder_decoder_layers)\n",
    "\n",
    "        # embeddings\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedded_dim)\n",
    "\n",
    "        # build decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embedded_dim, nhead=encoder_decoder_heads, batch_first=True)\n",
    "        self.decoders = nn.TransformerDecoder(decoder_layer, encoder_decoder_layers)\n",
    "\n",
    "        # final\n",
    "        self.linear = nn.Linear(in_features=768, out_features=vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        x = images\n",
    "        with torch.no_grad():\n",
    "            x = self.swin(x)\n",
    "        x = self.encoders(x.last_hidden_state)\n",
    "        \n",
    "        captions = self.embeddings(captions)\n",
    "        x = self.decoders(tgt=captions.to(x.dtype), memory=x)\n",
    "        return self.linear(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "Trains the model and saves the best (lowest val error) and last model\n",
    "\n",
    "This section does the following actions:\n",
    "1. Creates the Basic transformer model\n",
    "2. Sets up optimizer, scheduler, counter for training\n",
    "3. Trains for num_epochs epochs\n",
    "2. Each Epoch has valadation accuracy calculated\n",
    "3. Save the model with the best valadation accuracy TODO\n",
    "4. Save the model when the max number of epochs has been reached TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/4418 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinModelOutput(last_hidden_state=tensor([[[ 3.0675e-01,  5.0945e-01,  1.7325e-01,  ...,  1.1788e-01,\n",
      "          -3.1754e-01,  4.1218e-01],\n",
      "         [-8.1517e-01,  2.1400e-01, -4.5147e-01,  ...,  8.6758e-03,\n",
      "          -6.0718e-01,  2.1204e-01],\n",
      "         [-6.3092e-01,  1.8830e-01, -5.9638e-01,  ...,  1.0285e-01,\n",
      "          -5.0117e-01,  1.5747e-01],\n",
      "         ...,\n",
      "         [-4.8707e-01,  5.3982e-01, -4.8427e-01,  ..., -9.9385e-02,\n",
      "          -6.2420e-01,  8.4653e-02],\n",
      "         [-6.4340e-01,  3.8748e-01, -2.9780e-01,  ..., -2.2808e-01,\n",
      "          -6.6858e-01,  4.5301e-02],\n",
      "         [ 3.0318e-01,  4.8212e-01,  4.9809e-02,  ..., -1.5281e-02,\n",
      "          -4.1127e-01,  4.0977e-01]],\n",
      "\n",
      "        [[ 3.4669e-01,  1.0651e-01,  2.1525e-01,  ...,  1.8687e-01,\n",
      "           2.9659e-02, -1.4759e-02],\n",
      "         [ 2.5557e-01,  7.6197e-01, -7.0156e-01,  ..., -3.1938e+00,\n",
      "           1.3024e-01,  3.0944e-01],\n",
      "         [-1.4593e+00,  5.5855e-01,  6.8674e-01,  ..., -4.4938e-01,\n",
      "           3.0534e-01, -5.4908e-01],\n",
      "         ...,\n",
      "         [ 1.9431e-01, -5.5964e-01,  4.0891e-01,  ..., -3.4634e-01,\n",
      "          -7.2823e-01,  2.1355e+00],\n",
      "         [-7.8614e-02,  3.8402e-01,  3.0451e-01,  ..., -8.0456e-02,\n",
      "           1.1270e-01, -2.2538e-01],\n",
      "         [-3.6313e-01,  7.9929e-01,  2.9610e-01,  ...,  7.4375e-03,\n",
      "           4.1925e-01, -1.6077e-02]],\n",
      "\n",
      "        [[-3.5389e-01,  5.5421e-01, -1.1047e-01,  ...,  2.4549e-01,\n",
      "           3.7464e-01,  2.4462e-01],\n",
      "         [-2.0902e+00,  4.5363e-01, -8.2678e-01,  ...,  2.4554e-01,\n",
      "           8.8295e-01,  3.3937e-01],\n",
      "         [-1.1713e+00, -1.3503e+00,  1.9215e-01,  ..., -2.5525e-01,\n",
      "          -5.9510e-01,  1.9889e+00],\n",
      "         ...,\n",
      "         [-9.7721e-01,  1.2655e+00,  1.3040e+00,  ..., -1.1942e+00,\n",
      "          -3.1909e-02, -5.7050e-01],\n",
      "         [-5.8748e-01,  1.1333e+00,  2.2462e-01,  ..., -5.2599e-01,\n",
      "           2.4066e-01,  1.5436e-01],\n",
      "         [-3.7641e-01, -5.3958e-02, -2.1784e-01,  ...,  3.0177e-01,\n",
      "           4.2634e-01,  2.2518e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1536e-01, -6.1377e-02,  2.0248e-01,  ...,  1.2810e-01,\n",
      "           4.1123e-01,  2.1016e-01],\n",
      "         [-7.9073e-01,  1.7757e+00, -1.4087e+00,  ...,  3.1623e-01,\n",
      "          -2.2323e+00, -6.6862e-03],\n",
      "         [-1.9275e+00,  5.4231e-01, -8.5156e-01,  ..., -6.4673e-01,\n",
      "           4.4385e-01, -7.3995e-01],\n",
      "         ...,\n",
      "         [-8.4431e-01,  7.4691e-04, -3.8955e-01,  ...,  7.9424e-02,\n",
      "          -1.0728e-01,  2.4187e-02],\n",
      "         [-8.1616e-01,  1.9908e-01, -2.4244e-01,  ...,  1.9333e-01,\n",
      "           1.3063e-01,  3.5704e-02],\n",
      "         [ 5.0891e-03, -3.2202e-01, -1.5531e-01,  ...,  1.5253e-01,\n",
      "           3.1608e-01,  2.0639e-01]],\n",
      "\n",
      "        [[ 2.5526e-01, -3.3894e-01,  3.8986e-01,  ...,  2.0715e-01,\n",
      "           3.5417e-02,  1.2599e-01],\n",
      "         [-8.5763e-01,  3.8373e-01, -1.5518e-01,  ...,  2.8610e-01,\n",
      "          -6.7190e-01, -4.3793e-01],\n",
      "         [ 3.0461e-01, -8.7609e-01, -2.6141e-01,  ...,  3.7641e-01,\n",
      "          -2.2202e-01, -8.0301e-01],\n",
      "         ...,\n",
      "         [ 2.2972e-02,  2.7572e-01,  3.5723e-01,  ..., -5.2125e-01,\n",
      "          -7.3336e-01,  1.5396e+00],\n",
      "         [-1.5823e+00,  2.0293e+00, -1.5197e+00,  ..., -6.7609e-01,\n",
      "          -1.3558e+00,  7.5144e-01],\n",
      "         [ 2.9929e-01, -6.3201e-01,  4.6550e-02,  ...,  1.5492e-01,\n",
      "          -3.3489e-02,  1.4420e-01]],\n",
      "\n",
      "        [[-3.1833e-01,  1.5611e-01,  2.0978e-01,  ...,  2.1960e-01,\n",
      "           8.3730e-01, -3.5252e-01],\n",
      "         [-3.3698e-01, -7.9365e-01, -4.4503e-01,  ...,  3.8363e-01,\n",
      "           3.1308e-01, -4.9038e-01],\n",
      "         [-6.5095e-02,  6.3284e-02,  1.0679e-01,  ..., -5.6327e-01,\n",
      "           4.9177e-01, -6.2202e-01],\n",
      "         ...,\n",
      "         [-1.0371e+00, -1.1816e+00, -2.2980e-01,  ...,  8.7932e-01,\n",
      "          -6.0044e-01, -1.3774e+00],\n",
      "         [-1.1519e-01, -2.2920e+00, -1.1228e+00,  ..., -6.2855e-01,\n",
      "           1.2854e+00, -4.9220e+00],\n",
      "         [ 6.7268e-01, -4.5395e-01,  8.9178e-02,  ...,  2.5582e-02,\n",
      "           4.2238e-01, -2.5844e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.2065,  0.7847, -0.1447,  ..., -0.0570, -0.9709,  0.1089],\n",
      "        [-0.6792,  0.1445, -0.3470,  ..., -0.1628, -0.0204, -0.2247],\n",
      "        [-1.1026,  0.8793,  0.1318,  ..., -0.8323,  0.0803,  0.1067],\n",
      "        ...,\n",
      "        [-0.9184,  0.2201, -0.1827,  ...,  0.0386,  0.1443,  0.0165],\n",
      "        [-0.1197,  0.1219, -0.5193,  ..., -0.8308, -0.6454,  0.3462],\n",
      "        [ 0.3452,  0.0710, -0.2158,  ...,  0.4089,  0.1058, -0.8492]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)\n",
      "tensor([[[ 4.8161e-01, -2.7247e-01,  1.2399e-01,  ...,  3.1977e-01,\n",
      "           2.3062e-01,  1.4552e-01],\n",
      "         [-5.3351e-01,  2.1801e-01, -1.1040e-01,  ..., -5.0183e-01,\n",
      "          -7.9475e-01, -2.3789e-01],\n",
      "         [ 8.1438e-01,  3.9177e-01, -5.6980e-01,  ...,  2.9771e-01,\n",
      "          -7.9952e-01,  1.4062e-01],\n",
      "         ...,\n",
      "         [-2.2266e-01,  1.3558e+00, -9.6321e-01,  ..., -4.0655e-01,\n",
      "          -7.1241e-01,  4.2588e-01],\n",
      "         [-4.8859e-01,  2.0225e-01, -7.1223e-01,  ..., -2.4018e-01,\n",
      "           1.1196e-01, -3.8615e-01],\n",
      "         [ 5.2623e-01, -5.6361e-01, -2.3445e-01,  ...,  2.0294e-01,\n",
      "           6.6218e-02,  1.6586e-02]],\n",
      "\n",
      "        [[ 2.2975e-01,  5.5461e-03,  1.1379e-01,  ...,  2.5326e-01,\n",
      "           2.5645e-01, -6.9714e-02],\n",
      "         [-1.0770e+00, -2.6785e-01, -2.1963e-01,  ...,  2.0549e-02,\n",
      "           3.0452e-01, -4.0780e-01],\n",
      "         [-1.2028e+00,  9.6210e-01,  6.1462e-01,  ..., -3.8550e-01,\n",
      "          -3.6238e-02, -4.6940e-01],\n",
      "         ...,\n",
      "         [-4.5921e-02, -1.0279e+00,  2.2138e-01,  ...,  1.0922e+00,\n",
      "          -1.9509e+00,  1.5025e+00],\n",
      "         [ 2.0204e-01, -2.1774e-01,  2.1793e-03,  ...,  1.9972e-01,\n",
      "           1.5269e-01, -1.1511e-01],\n",
      "         [-6.2251e-01,  8.2261e-01,  1.7495e-01,  ..., -2.8533e-01,\n",
      "           6.4271e-01, -3.3763e-01]],\n",
      "\n",
      "        [[-2.0082e-01,  6.4370e-01, -4.1373e-02,  ...,  2.3462e-01,\n",
      "           3.6393e-01,  2.9794e-01],\n",
      "         [-1.7701e+00,  5.7166e-01, -8.4233e-01,  ...,  2.8284e-01,\n",
      "           7.2638e-01,  3.4884e-01],\n",
      "         [-9.1666e-01, -5.1818e-01, -2.7057e-01,  ..., -2.6701e-01,\n",
      "           4.9548e-01,  1.8794e+00],\n",
      "         ...,\n",
      "         [-7.2862e-01,  9.7138e-01,  1.1588e+00,  ..., -9.6654e-01,\n",
      "          -2.8402e-01, -2.4008e-01],\n",
      "         [-5.0021e-01,  1.8235e+00,  1.0099e+00,  ..., -7.1364e-01,\n",
      "           3.0918e-01,  3.6351e-01],\n",
      "         [ 4.8262e-01, -1.7250e-01, -1.0188e-01,  ...,  2.2320e-01,\n",
      "           5.1238e-02,  4.3733e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.2112e-02,  1.8160e-02,  2.8867e-01,  ...,  3.1926e-01,\n",
      "           4.1407e-01,  1.5812e-01],\n",
      "         [-8.0291e-01,  1.9453e+00, -2.1792e+00,  ...,  3.0230e-01,\n",
      "          -1.9307e+00, -4.6038e-01],\n",
      "         [-2.0605e+00,  9.7100e-01, -1.4865e+00,  ..., -7.0748e-01,\n",
      "           7.1086e-01, -1.4936e+00],\n",
      "         ...,\n",
      "         [-9.2962e-01, -1.4423e-02, -4.1031e-01,  ...,  2.5634e-01,\n",
      "          -1.5241e-02, -1.3992e-01],\n",
      "         [-7.6026e-01,  2.2648e-01, -8.8342e-02,  ...,  3.5304e-01,\n",
      "           2.3624e-01,  1.8085e-02],\n",
      "         [ 1.1279e-03, -2.0421e-01, -8.1863e-02,  ...,  3.1453e-01,\n",
      "           3.1255e-01,  1.9229e-01]],\n",
      "\n",
      "        [[ 1.0799e-01, -1.6946e-01,  3.3731e-01,  ...,  2.0565e-01,\n",
      "           2.0835e-01,  8.5600e-02],\n",
      "         [-5.1141e-01,  2.8504e-01, -1.3073e-01,  ...,  2.3265e-01,\n",
      "          -3.4252e-01, -1.1687e+00],\n",
      "         [ 1.8275e-01, -7.5526e-01, -3.0815e-01,  ...,  2.8226e-01,\n",
      "           1.3678e-01, -7.1915e-01],\n",
      "         ...,\n",
      "         [-5.6944e-01,  4.9367e-01,  1.0571e-01,  ..., -9.0571e-01,\n",
      "          -1.1422e+00,  1.6516e+00],\n",
      "         [-1.0884e+00,  1.6993e+00, -2.0131e+00,  ..., -4.9586e-01,\n",
      "          -1.1914e+00,  5.6637e-01],\n",
      "         [ 1.7136e-01, -4.7392e-01, -5.4723e-02,  ...,  1.6264e-01,\n",
      "           1.6753e-01,  1.2532e-01]],\n",
      "\n",
      "        [[-1.9209e-01,  9.4184e-03,  5.3313e-01,  ...,  1.9620e-02,\n",
      "           5.0493e-02,  2.5999e-01],\n",
      "         [-5.7947e-01, -5.3619e-01, -5.2196e-01,  ...,  4.0153e-01,\n",
      "           1.3123e-01, -1.2725e-01],\n",
      "         [-2.8645e-02, -1.0902e-01,  2.7378e-01,  ...,  2.7432e-02,\n",
      "           9.8657e-02,  1.3429e-01],\n",
      "         ...,\n",
      "         [-1.0286e+00,  2.5079e-01,  7.9034e-01,  ..., -1.3908e+00,\n",
      "           1.5824e+00, -1.5488e+00],\n",
      "         [ 1.1300e+00, -8.1335e-01, -6.3471e-02,  ..., -1.0924e+00,\n",
      "           3.7171e+00, -2.3309e+00],\n",
      "         [ 2.3633e-01, -3.7445e-01,  3.0701e-01,  ..., -3.5741e-01,\n",
      "           7.8893e-02,  4.6677e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 1/4418 [00:04<5:42:04,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinModelOutput(last_hidden_state=tensor([[[ 5.2467e-01, -1.6158e-01,  3.2696e-02,  ...,  2.9319e-01,\n",
      "          -6.6524e-02,  1.4002e-01],\n",
      "         [ 2.0795e-01, -9.2373e-01, -1.6926e+00,  ...,  1.2636e-01,\n",
      "          -6.5223e-01,  1.0950e-01],\n",
      "         [-3.6473e-01, -1.6991e+00, -1.4850e+00,  ..., -1.2395e-01,\n",
      "          -6.0512e-01,  8.9079e-02],\n",
      "         ...,\n",
      "         [-9.9634e-02,  1.1863e+00,  1.4123e+00,  ...,  6.1957e+00,\n",
      "           2.4381e-01, -1.8393e+00],\n",
      "         [ 1.4298e-01,  1.1754e+00,  7.6745e-01,  ...,  5.5598e+00,\n",
      "          -4.3329e-01, -2.0899e+00],\n",
      "         [ 6.4411e-01, -4.9268e-01, -3.1999e-01,  ...,  2.8826e-01,\n",
      "          -1.4891e-01,  1.3572e-01]],\n",
      "\n",
      "        [[ 5.9943e-01,  6.7352e-02,  1.1703e-01,  ...,  4.4320e-01,\n",
      "          -1.8730e-02,  2.1719e-01],\n",
      "         [ 1.8858e-01,  1.1023e-01,  6.4541e-02,  ...,  2.3339e-01,\n",
      "           2.1339e-01,  2.0589e-01],\n",
      "         [-7.5265e-02,  1.1456e-01, -2.2233e-01,  ...,  2.8940e-01,\n",
      "          -3.9021e-02,  8.4188e-02],\n",
      "         ...,\n",
      "         [ 3.4765e-01,  2.3968e+00, -4.5900e-01,  ...,  6.6455e-01,\n",
      "          -1.8272e-01,  2.7944e-01],\n",
      "         [ 1.1779e-01,  1.4570e+00,  2.1782e-01,  ...,  5.8138e-01,\n",
      "           5.7133e-01,  3.5497e-01],\n",
      "         [-2.1736e-01, -9.3677e-02, -8.6905e-01,  ...,  4.6030e-01,\n",
      "           1.1437e-02,  2.6453e-01]],\n",
      "\n",
      "        [[ 4.1176e-01, -1.0823e-01,  1.2795e-01,  ...,  4.1919e-01,\n",
      "           2.0025e-01,  3.9243e-01],\n",
      "         [ 8.6691e-01, -2.8972e-02, -2.8671e+00,  ...,  1.6315e+00,\n",
      "          -1.0038e+00, -3.1700e-01],\n",
      "         [-7.9266e-02,  6.4604e-02, -4.1360e-02,  ...,  1.7328e-01,\n",
      "           3.4342e-01, -3.2065e-01],\n",
      "         ...,\n",
      "         [-5.3848e-01, -3.5789e-02, -9.7132e-01,  ...,  4.3555e-01,\n",
      "           7.0283e-01, -1.3464e-02],\n",
      "         [-4.3367e-01,  1.3769e-01, -8.6940e-02,  ...,  3.9984e-01,\n",
      "           3.9350e-01,  6.5982e-02],\n",
      "         [ 3.2633e-01, -6.9263e-02, -2.0921e-02,  ...,  3.2470e-01,\n",
      "           1.4571e-01,  3.2141e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.5800e-01, -5.4686e-01,  5.5222e-01,  ...,  7.1806e-01,\n",
      "           5.0201e-01,  1.2282e-01],\n",
      "         [-3.7995e-01, -8.3299e-01, -6.1736e-01,  ..., -7.5595e-02,\n",
      "          -7.2617e-01,  5.2293e-01],\n",
      "         [-7.1783e-01, -7.6616e-01, -6.7004e-01,  ..., -7.8352e-02,\n",
      "          -6.3231e-01,  3.0830e-01],\n",
      "         ...,\n",
      "         [-5.9508e-01, -6.4875e-01, -8.0748e-02,  ..., -5.8459e-01,\n",
      "          -6.6262e-01,  1.3601e-01],\n",
      "         [-2.7374e-01, -5.5915e-01, -5.7016e-02,  ..., -6.9416e-01,\n",
      "          -9.5351e-01,  3.1091e-01],\n",
      "         [ 2.5317e-01, -8.1730e-01,  1.6835e-01,  ..., -1.6381e-01,\n",
      "          -4.3179e-01,  2.7554e-01]],\n",
      "\n",
      "        [[ 5.9435e-02, -1.4144e-01,  4.7940e-01,  ...,  1.4808e-01,\n",
      "           2.6761e-01,  3.4962e-01],\n",
      "         [-3.6764e-01, -4.0676e-01,  8.0014e-02,  ..., -1.6019e-01,\n",
      "           7.1573e-01,  8.0361e-02],\n",
      "         [-1.4638e+00, -1.9679e+00,  1.5898e+00,  ..., -3.5542e+00,\n",
      "           9.4288e-01,  2.4610e+00],\n",
      "         ...,\n",
      "         [-7.1340e-01,  9.6519e-02, -4.1031e-01,  ..., -9.0882e-01,\n",
      "          -7.5232e-02, -8.8327e-01],\n",
      "         [ 2.7987e+00,  1.0833e+00, -5.5107e-01,  ..., -1.1848e+00,\n",
      "          -7.2802e-01,  2.8189e-01],\n",
      "         [ 5.7305e-02, -5.2360e-01,  2.3468e-01,  ...,  6.4494e-02,\n",
      "           1.6755e-01,  3.2781e-01]],\n",
      "\n",
      "        [[ 4.5685e-01, -7.5470e-02,  3.2334e-01,  ...,  3.8951e-01,\n",
      "           2.1951e-01, -2.4214e-01],\n",
      "         [-2.2939e+00,  1.1128e+00, -2.4813e-01,  ..., -1.5592e-01,\n",
      "          -1.4511e+00,  1.7946e-01],\n",
      "         [-2.4179e-01,  1.5700e+00, -9.6171e-01,  ..., -3.2149e-01,\n",
      "          -5.2146e-01, -8.6338e-01],\n",
      "         ...,\n",
      "         [ 2.0737e+00, -1.6533e-01, -3.8884e-01,  ...,  1.2691e-01,\n",
      "           1.4893e+00, -2.0088e+00],\n",
      "         [ 6.6070e-01,  1.6611e+00,  1.6844e-01,  ..., -1.0800e+00,\n",
      "           8.1765e-01,  2.2006e-01],\n",
      "         [-1.2458e-01,  1.2119e+00, -6.8326e-01,  ...,  1.6225e+00,\n",
      "          -2.3837e-03, -3.7725e+00]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.8907,  0.5750, -0.1646,  ...,  0.3491, -0.7836, -0.9362],\n",
      "        [-0.0581,  0.5685, -0.3960,  ...,  0.4082,  0.3109, -0.0534],\n",
      "        [ 0.3646,  1.6062, -2.3461,  ...,  1.2485,  0.9300,  0.3578],\n",
      "        ...,\n",
      "        [-0.5701, -0.3770, -0.1891,  ..., -0.1667, -0.4530,  0.1308],\n",
      "        [ 0.6393, -0.3552,  0.5183,  ..., -0.1979,  0.2748, -0.1059],\n",
      "        [-0.0862,  1.1650, -0.6448,  ...,  0.3006, -0.1672, -1.7367]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None, reshaped_hidden_states=None)\n",
      "tensor([[[ 3.0282e-01, -4.2691e-01,  9.1817e-02,  ...,  2.8062e-01,\n",
      "          -5.2197e-02,  2.3834e-02],\n",
      "         [-2.8694e-02, -1.4247e+00, -1.9833e+00,  ..., -2.1187e-01,\n",
      "          -5.1855e-01,  2.8146e-01],\n",
      "         [ 6.2623e-02, -2.3927e+00, -2.2564e+00,  ..., -8.6089e-01,\n",
      "          -5.7505e-01,  4.9154e-01],\n",
      "         ...,\n",
      "         [ 1.1904e+00,  6.5746e-01,  1.5411e+00,  ...,  6.3795e+00,\n",
      "          -6.1432e-01, -8.6092e-01],\n",
      "         [ 7.2926e-01,  5.5079e-01,  6.7319e-01,  ...,  3.6417e+00,\n",
      "          -1.2604e+00, -6.4799e-01],\n",
      "         [ 4.1149e-01, -7.9663e-01, -2.6547e-01,  ...,  2.6111e-01,\n",
      "          -2.6296e-01,  1.1452e-01]],\n",
      "\n",
      "        [[ 6.4478e-01, -2.4464e-02, -2.2745e-01,  ...,  6.6209e-01,\n",
      "          -3.5116e-01,  2.5117e-03],\n",
      "         [-1.0997e-01, -2.8370e-01, -1.1907e+00,  ...,  5.1319e-01,\n",
      "          -1.3498e+00, -4.4988e-01],\n",
      "         [-8.2051e-01, -1.9272e-01, -1.0220e+00,  ...,  5.7079e-01,\n",
      "          -5.3608e-01, -2.4363e-01],\n",
      "         ...,\n",
      "         [ 1.0336e-01,  1.2003e+00, -2.0940e-03,  ...,  1.2227e+00,\n",
      "          -1.4942e-02, -3.3812e-01],\n",
      "         [ 5.8698e-01,  1.3901e+00,  1.0399e+00,  ...,  5.2417e-01,\n",
      "           1.9689e-01,  3.9558e-02],\n",
      "         [-4.1813e-01,  3.4510e-01, -7.4728e-01,  ...,  4.3358e-01,\n",
      "          -3.9199e-01,  1.8115e-01]],\n",
      "\n",
      "        [[-1.4089e+00, -1.3901e+00, -7.0011e-01,  ..., -2.4406e+00,\n",
      "          -5.7319e-02,  4.3253e-01],\n",
      "         [-4.8729e-01,  3.0327e-01, -5.2498e-02,  ...,  1.1062e-01,\n",
      "           4.9521e-01, -1.1954e-01],\n",
      "         [ 1.3856e-01,  1.9800e-01, -1.2400e-01,  ..., -3.8804e-02,\n",
      "           6.8142e-01,  3.1934e-01],\n",
      "         ...,\n",
      "         [ 3.2138e-01,  9.0702e-01, -1.1469e+00,  ..., -7.7165e-01,\n",
      "           7.7968e-01, -2.2821e-01],\n",
      "         [-2.1009e-01,  9.6523e-02, -1.2337e-01,  ..., -1.9655e+00,\n",
      "          -3.4957e-02, -1.2505e+00],\n",
      "         [-8.9716e-01,  2.2655e-01, -2.6332e-01,  ..., -3.7148e-01,\n",
      "           5.2146e-01, -6.1133e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.4763e-01, -4.4175e-01,  7.6114e-01,  ...,  4.3845e-01,\n",
      "           4.6018e-01,  5.6924e-02],\n",
      "         [-3.2043e-01, -7.1607e-01, -5.3621e-01,  ..., -5.0131e-02,\n",
      "          -5.9034e-01,  4.8566e-01],\n",
      "         [-7.1747e-01, -7.1553e-01, -6.5528e-01,  ..., -6.5713e-02,\n",
      "          -5.8644e-01,  3.0399e-01],\n",
      "         ...,\n",
      "         [-6.4679e-01, -6.0531e-01, -1.4775e-01,  ..., -5.5103e-01,\n",
      "          -6.7592e-01,  1.4823e-01],\n",
      "         [-3.5899e-01, -5.7070e-01, -1.3077e-01,  ..., -6.9281e-01,\n",
      "          -9.5365e-01,  3.1749e-01],\n",
      "         [ 2.4041e-01, -7.8889e-01,  2.0666e-01,  ..., -1.7339e-01,\n",
      "          -4.7478e-01,  2.8373e-01]],\n",
      "\n",
      "        [[ 1.7465e-01, -2.0345e-02,  6.2046e-01,  ...,  9.0658e-02,\n",
      "           3.2251e-01,  3.7118e-01],\n",
      "         [-3.8989e-01, -1.5348e+00,  6.5825e-01,  ..., -1.0387e+00,\n",
      "           7.1266e-01,  2.4867e-01],\n",
      "         [-1.6270e+00, -2.3243e+00,  1.5194e+00,  ..., -3.0003e+00,\n",
      "           9.3979e-01,  1.8687e+00],\n",
      "         ...,\n",
      "         [ 2.9731e-01,  3.4000e-02, -5.7612e-01,  ..., -1.4364e+00,\n",
      "          -1.0276e+00, -5.1100e-01],\n",
      "         [ 3.2925e+00,  1.4720e+00, -3.9087e-01,  ..., -1.0732e+00,\n",
      "          -2.3955e-01,  9.7082e-01],\n",
      "         [ 1.5648e-01, -4.2072e-01,  4.1751e-01,  ..., -1.7710e-02,\n",
      "           1.9308e-01,  3.0687e-01]],\n",
      "\n",
      "        [[ 3.7087e-01, -1.3566e-01,  2.1132e-01,  ...,  5.9879e-01,\n",
      "           2.2976e-01, -8.9540e-02],\n",
      "         [-2.0067e+00,  4.3827e-01, -6.0981e-01,  ...,  4.6164e-01,\n",
      "          -1.0649e+00,  5.7506e-01],\n",
      "         [ 1.3629e+00,  2.9478e+00, -2.7448e+00,  ..., -7.0856e-01,\n",
      "          -1.1059e+00, -1.7008e+00],\n",
      "         ...,\n",
      "         [ 9.5236e-01,  3.0475e-03, -1.8943e-01,  ..., -2.2737e+00,\n",
      "           1.0556e+00,  4.0168e-01],\n",
      "         [ 2.4032e+00, -2.8760e-01, -1.3659e+00,  ...,  1.2261e+00,\n",
      "           8.7071e-01,  1.1073e+00],\n",
      "         [-2.9051e-01,  9.5907e-01, -1.5154e+00,  ...,  5.1712e-01,\n",
      "          -7.0653e-01, -2.7574e+00]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# save loss\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss so far is: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m (train_loss \u001b[38;5;241m/\u001b[39m i))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Loop setup\n",
    "model = BasicCaptionTransformer()\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "# Train\n",
    "predictions_per_batch = batch_size * max_length\n",
    "stop_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "train_len = len(train_dataset_loader)\n",
    "val_len = len(valid_dataset_loader)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Loop through training data loader batches\n",
    "    train_loss = 0.0\n",
    "    train_dataloader_iter = tqdm(train_dataset_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    for i, data in enumerate(train_dataloader_iter):\n",
    "        \n",
    "        # Get values from data loader\n",
    "        pixel_vals = data[\"pixel_values\"].to(device)\n",
    "        captions = data[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images=pixel_vals, captions=captions) # outputs are NAN... bad...\n",
    "\n",
    "        loss = loss_function(outputs.permute(0,2,1), captions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # save loss\n",
    "        train_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print (\"Loss so far is: \" + str (train_loss / i))\n",
    "            print (\"tensor: \", outputs)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    valid_dataset_iter = tqdm(valid_dataset_loader,  desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "    for i, data in enumerate(valid_dataset_iter):\n",
    "        \n",
    "        # Get values from data loader\n",
    "        pixel_vals = data[\"pixel_values\"].to(device)\n",
    "        captions = data[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(images=pixel_vals, captions=captions)\n",
    "        loss = loss_function(outputs.permute(0,2,1), captions)\n",
    "\n",
    "        # save loss\n",
    "        val_loss += loss.item()\n",
    "\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f'./models/model_epoch_{epoch+1}.pt')\n",
    "\n",
    "    train_losses.append(train_loss / train_len)\n",
    "    val_losses.append(val_loss / val_len)\n",
    "\n",
    "    # Print losses\n",
    "    # divide by length of data loader... \n",
    "    print(\"\\nEpoch: \" + str(epoch) + \n",
    "        \"\\nTrain Loss: \" + str(train_loss / train_len) +\n",
    "        \"\\nVal Loss: \" + str(val_loss / val_len))\n",
    "\n",
    "print (train_losses)\n",
    "print (val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Training Metrics\n",
    "Computes the test loss and common test metrics\n",
    "\n",
    "This section does the following actions:\n",
    "1. Loads the specified model\n",
    "2. Runs through the test set and reports loss\n",
    "3. Runs through the val set for BLEU and ROUGE metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set Progress:   0%|          | 1/390 [00:00<03:24,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   32,   582,   351,  ..., 50256, 50256, 50256],\n",
      "        [ 5124, 10311,   257,  ..., 50256, 50256, 50256],\n",
      "        [   32,   582, 10311,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   32,  7684,   286,  ..., 50256, 50256, 50256],\n",
      "        [   64,   736, 12525,  ..., 50256, 50256, 50256],\n",
      "        [   32,  1271,   286,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set Progress:   1%|          | 2/390 [00:01<03:26,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   64,  7684,   286,  ..., 50256, 50256, 50256],\n",
      "        [   32, 39145,  2330,  ..., 50256, 50256, 50256],\n",
      "        [   32, 28774,  5017,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   32, 27638,   286,  ..., 50256, 50256, 50256],\n",
      "        [14945, 15900, 40470,  ..., 50256, 50256, 50256],\n",
      "        [13247,   286, 15900,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set Progress:   1%|          | 3/390 [00:01<03:35,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   32, 29556,   286,  ..., 50256, 50256, 50256],\n",
      "        [ 3347,   538,   389,  ..., 50256, 50256, 50256],\n",
      "        [   32, 29556,   286,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   32,  9875,   319,  ..., 50256, 50256, 50256],\n",
      "        [  464,  5044,   318,  ..., 50256, 50256, 50256],\n",
      "        [   32,  7586,  9875,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set Progress:   1%|          | 4/390 [00:02<03:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   32,  9875,   318,  ..., 50256, 50256, 50256],\n",
      "        [   32,  6473,  5055,  ..., 50256, 50256, 50256],\n",
      "        [   64,  7586,   290,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   32,  2415, 10718,  ..., 50256, 50256, 50256],\n",
      "        [   32,  2415,  5586,  ..., 50256, 50256, 50256],\n",
      "        [   32,  2415,  5586,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Set Progress:   1%|▏         | 5/390 [00:02<03:35,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   64,  2415, 10718,  ..., 50256, 50256, 50256],\n",
      "        [   32,  2576,   351,  ..., 50256, 50256, 50256],\n",
      "        [   32,  2415,   351,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   32,  2415,   318,  ..., 50256, 50256, 50256],\n",
      "        [   32,  2415,   318,  ..., 50256, 50256, 50256],\n",
      "        [   64,  2415,  1016,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   32,   582, 10311,  ..., 50256, 50256, 50256],\n",
      "        [   32, 17876,  7976,  ..., 50256, 50256, 50256],\n",
      "        [   32,  8223,  1891,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 7571,  1862, 22647,  ..., 50256, 50256, 50256],\n",
      "        [ 7571,  1862,  1450,  ..., 50256, 50256, 50256],\n",
      "        [ 1858,   389,   734,  ..., 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     30\u001b[0m        test_dataset_iter \u001b[38;5;241m=\u001b[39m tqdm(test_dataset_loader,  desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Set Progress: \u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_dataset_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# get data from batch\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpixel_vals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpixel_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:2865\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[1;34m(self, keys)\u001b[0m\n\u001b[0;32m   2863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[0;32m   2864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2865\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2866\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m   2867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\formatting\\formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\formatting\\formatting.py:401\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\datasets\\formatting\\formatting.py:516\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    514\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[0;32m    515\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(items):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Image pre-processing\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# use ViT and SWIN since no back prob\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m \u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpixel_values\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m#pixel_values = image_processor_swin(pixel_values)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# tokenize captions\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     targets \u001b[38;5;241m=\u001b[39m tokenizer([sentence[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m items[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     34\u001b[0m                         max_length\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\transformers\\image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[1;34m(self, images, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[0;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\transformers\\models\\vit\\image_processing_vit.py:268\u001b[0m, in \u001b[0;36mViTImageProcessor.preprocess\u001b[1;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m infer_channel_dimension_format(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[0;32m    267\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 268\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[0;32m    270\u001b[0m     ]\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_rescale:\n\u001b[0;32m    273\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale(image\u001b[38;5;241m=\u001b[39mimage, scale\u001b[38;5;241m=\u001b[39mrescale_factor, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[0;32m    276\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\transformers\\models\\vit\\image_processing_vit.py:153\u001b[0m, in \u001b[0;36mViTImageProcessor.resize\u001b[1;34m(self, image, size, resample, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `size` dictionary must contain the keys `height` and `width`. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m output_size \u001b[38;5;241m=\u001b[39m (size[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m], size[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\transformers\\image_transforms.py:327\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, size, resample, reducing_gap, data_format, return_numpy, input_data_format)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    326\u001b[0m     do_rescale \u001b[38;5;241m=\u001b[39m _rescale_for_pil_conversion(image)\n\u001b[1;32m--> 327\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mto_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_rescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_rescale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m height, width \u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# PIL images are in the format (width, height)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\transformers\\image_transforms.py:205\u001b[0m, in \u001b[0;36mto_pil_image\u001b[1;34m(image, do_rescale, input_data_format)\u001b[0m\n\u001b[0;32m    202\u001b[0m     image \u001b[38;5;241m=\u001b[39m rescale(image, \u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    204\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\PIL\\Image.py:3122\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3120\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[1;32m-> 3122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\PIL\\Image.py:3037\u001b[0m, in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3034\u001b[0m         im\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3035\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[1;32m-> 3037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\PIL\\Image.py:2970\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2946\u001b[0m \u001b[38;5;124;03mCreates a copy of an image memory from pixel data in a buffer.\u001b[39;00m\n\u001b[0;32m   2947\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2965\u001b[0m \u001b[38;5;124;03m:returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m   2966\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2968\u001b[0m _check_size(size)\n\u001b[1;32m-> 2970\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m im\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2972\u001b[0m     \u001b[38;5;66;03m# may pass tuple instead of argument list\u001b[39;00m\n\u001b[0;32m   2973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32mc:\\Programming\\Python3-12-3\\Lib\\site-packages\\PIL\\Image.py:2941\u001b[0m, in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m ImagePalette\u001b[38;5;241m.\u001b[39mImagePalette()\n\u001b[0;32m   2940\u001b[0m     color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color)\n\u001b[1;32m-> 2941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import EvalPrediction\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model\n",
    "MODEL_PATH = \"./models/model_epoch_8.pt\"\n",
    "LOAD_MODEL = True\n",
    "\n",
    "eval_model = None\n",
    "if LOAD_MODEL:\n",
    "       if \"model\" in locals():\n",
    "              model.to('cpu')\n",
    "\n",
    "       eval_model = BasicCaptionTransformer()\n",
    "       eval_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "       eval_model = eval_model.to(device)\n",
    "\n",
    "else:\n",
    "       eval_model = model\n",
    "\n",
    "# Eval setup\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "test_loss = 0.0\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "# Run through the test for test loss\n",
    "with torch.no_grad():\n",
    "       test_dataset_iter = tqdm(test_dataset_loader,  desc=f'Test Set Progress: ', leave=False)\n",
    "       for data in test_dataset_iter:\n",
    "\n",
    "              # get data from batch\n",
    "              pixel_vals = data[\"pixel_values\"].to(device)\n",
    "              labels = data[\"labels\"].to(device)\n",
    "\n",
    "              # Predict captions\n",
    "              outputs = eval_model(images=pixel_vals, captions=labels)\n",
    "              test_loss += loss_function(outputs.permute(0,2,1), labels)\n",
    "              print (test_loss)\n",
    "\n",
    "print (\"Test Loss: \" + str(test_loss / len(test_dataset_loader)))\n",
    "\n",
    "\n",
    "# Run through valadation set with best model\n",
    "predictions = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "       for data in valid_dataset_loader:\n",
    "\n",
    "              # get data from batch\n",
    "              pixel_vals = data[\"pixel_values\"].to(device)\n",
    "              labels = data[\"labels\"].to(device)\n",
    "       \n",
    "              # Predict captions\n",
    "              outputs = eval_model(images=pixel_vals, captions=labels)\n",
    "\n",
    "              # Format labels\n",
    "              logits = outputs.detach().cpu()\n",
    "              predictions.extend(logits.argmax(dim=-1).tolist())\n",
    "              labels.extend(labels.tolist())\n",
    "    \n",
    "\n",
    "# Format predictions into Hugging Face class\n",
    "eval_predictions = EvalPrediction(predictions=predictions, label_ids=labels)\n",
    "\n",
    "predictions = eval_predictions.predictions\n",
    "labels = eval_predictions.label_ids\n",
    "\n",
    "# Tokenize predictions and reference captions\n",
    "predictions_str = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "labels_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Load test evaluators\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Compute and print Rouge-1, Rogue-2, RougeL\n",
    "rouge_result = rouge.compute(predictions=predictions_str, references=labels_str)\n",
    "rouge_result = {k: round(v * 100, 4) for k, v in rouge_result.items()}\n",
    "print (\"ROUGE Metrics: \\nROUGE-1: \" + rouge_result.get(\"rouge1\", 0) + \n",
    "       \"\\nROUGE-2: \" + rouge_result.get(\"rouge2\", 0) + \n",
    "       \"\\nROUGE-L: \" + rouge_result.get(\"rougeL\", 0))\n",
    "\n",
    "\n",
    "# Compute and print BLEU metrics\n",
    "bleu_result = bleu.compute(predictions=predictions_str, references=labels_str)\n",
    "bleu_score = round(bleu_result[\"bleu\"] * 100, 4)\n",
    "print (\"BLEU Metrics: \" + bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
