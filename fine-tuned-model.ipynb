{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7e25b5-aa3f-47ea-94c0-f329120f8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers peft accelerate optimum einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39bb7379-efb4-48bf-943c-609d23367ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (2.3.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==2.3.0 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: requests in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.32.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91923f04-d2a8-4873-9c0a-907a26a7c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import urllib.parse as parse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import (VisionEncoderDecoderModel, GPT2TokenizerFast, ViTImageProcessor, \n",
    "                          Seq2SeqTrainingArguments, Seq2SeqTrainer, pipeline, EvalPrediction)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import evaluate\n",
    "\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc966dad-cf3d-4908-9b26-e6b02cb8a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "world_size = torch.cuda.device_count()\n",
    "print(world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573dfd84-09e5-482a-b192-b9604f70bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/stak/users/arulmozg/hpc-share/huggingface/hub\n",
      "/nfs/stak/users/arulmozg/hpc-share/huggingface\n"
     ]
    }
   ],
   "source": [
    "print(transformers.file_utils.default_cache_path)\n",
    "print(datasets.config.HF_DATASETS_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d180c125-e93f-43e5-8aff-5101f72b91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddp_setup(rank, world_size):\n",
    "    # Initialize the process group\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "    \n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aba39d9-9a7e-40be-a498-7c77a71a0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url(string):\n",
    "    try:\n",
    "        result = parse.urlparse(string)\n",
    "        return all([result.scheme, result.netloc, result.path])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def load_image(image_path):\n",
    "    if is_url(image_path):\n",
    "        return Image.open(requests.get(image_path, stream=True).raw)\n",
    "    elif os.path.exists(image_path):\n",
    "        return Image.open(image_path)\n",
    "\n",
    "def preprocess(items):\n",
    "    pixel_values = image_processor(items[\"image\"], return_tensors=\"pt\").pixel_values.to(device)\n",
    "    targets = tokenizer([sentence[\"raw\"] for sentence in items[\"sentences\"]],\n",
    "                        max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "    return {'pixel_values': pixel_values, 'labels': targets[\"input_ids\"]}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7262e9ab-22b3-45c5-8ba7-3ec21f34ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for HuggingFaceM4/COCO contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/HuggingFaceM4/COCO\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = 32\n",
    "coco_dataset_ratio = 50\n",
    "train_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"train[:{coco_dataset_ratio}%]\")\n",
    "valid_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"validation[:{coco_dataset_ratio}%]\")\n",
    "test_ds = load_dataset(\"HuggingFaceM4/COCO\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885682b3-c533-4c9e-89d8-3522508b576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds = train_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=world_size)\n",
    "valid_ds = valid_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=world_size)\n",
    "test_ds = test_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=world_size)\n",
    "\n",
    "train_dataset = train_ds.with_transform(preprocess)\n",
    "valid_dataset = valid_ds.with_transform(preprocess)\n",
    "test_dataset = test_ds.with_transform(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdd4790-1caf-4a37-be78-3e00ee3873ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size, rank, world_size):\n",
    "\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    valid_sampler = DistributedSampler(valid_dataset, num_replicas=world_size, rank=rank)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310d1249-220c-405b-88f5-9ad33d5daffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, pixel_values, labels):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, valid_loader, rank):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(rank)\n",
    "            label_ids = batch[\"labels\"].to(rank)\n",
    "            outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
    "            loss = outputs.loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits.detach().cpu()\n",
    "            predictions.extend(logits.argmax(dim=-1).tolist())\n",
    "            labels.extend(label_ids.tolist())\n",
    "\n",
    "    avg_val_loss = valid_loss / len(valid_loader)\n",
    "    return avg_val_loss, predictions, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac48bb46-5cba-4948-a7a7-7feb4d18fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred, tokenizer):\n",
    "    preds = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute ROUGE\n",
    "    rouge_result = rouge.compute(predictions=pred_str, references=labels_str)\n",
    "    rouge_result = {k: round(v * 100, 4) for k, v in rouge_result.items()}\n",
    "\n",
    "    # Compute BLEU\n",
    "    bleu_result = bleu.compute(predictions=pred_str, references=labels_str)\n",
    "    bleu_score = round(bleu_result[\"bleu\"] * 100, 4)\n",
    "\n",
    "    # Compute SPICE\n",
    "    spice_result = compute_spice(pred_str, labels_str)\n",
    "    spice_score = round(spice_result[\"spice\"], 4)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_result.get(\"rouge1\", 0),\n",
    "        \"rouge2\": rouge_result.get(\"rouge2\", 0),\n",
    "        \"rougeL\": rouge_result.get(\"rougeL\", 0),\n",
    "        \"bleu\": bleu_score,\n",
    "        \"spice\": spice_score\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_spice(predictions, references):\n",
    "    spice = Spice()\n",
    "    \n",
    "    # Create dictionaries for gts and res\n",
    "    res = {i: [pred] for i, pred in enumerate(predictions)}\n",
    "    gts = {i: [ref] for i, ref in enumerate(references)}\n",
    "    \n",
    "    # Compute SPICE score\n",
    "    average_score, scores = spice.compute_score(gts, res)\n",
    "    return {\"spice\": average_score}\n",
    "\n",
    "def get_evaluation_metrics(model, dataset):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=batch_size)\n",
    "    n_test_steps = len(dataloader)\n",
    "    predictions, labels = [], []\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(dataloader, \"Evaluating\"):\n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        label_ids = batch[\"labels\"]\n",
    "        outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "        logits = outputs.logits.detach().cpu()\n",
    "        predictions.extend(logits.argmax(dim=-1).tolist())\n",
    "        labels.extend(label_ids.tolist())\n",
    "    eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
    "    metrics = compute_metrics(eval_prediction)\n",
    "    metrics[\"test_loss\"] = test_loss / n_test_steps\n",
    "    return metrics\n",
    "\n",
    "def get_caption(model, image_processor, tokenizer, image_path):\n",
    "    image = load_image(image_path)\n",
    "    img = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**img)\n",
    "    caption = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    return caption\n",
    "\n",
    "def show_image_and_captions(url):\n",
    "    display(load_image(url))\n",
    "    our_caption = get_caption(best_model, image_processor, tokenizer, url)\n",
    "    pipeline_caption = get_caption(image_captioner.model, image_processor, tokenizer, url)\n",
    "    print(f\"Our caption: {our_caption}\")\n",
    "    print(f\"Abdou/vit-swin-base-224-gpt2-image-captioning caption: {pipeline_caption}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4787df8a-0250-4ad3-8724-36e23f62d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# File to log training metrics\\nlog_file = open(\"training_logs.txt\", \"w\")\\n\\n# number of training steps\\nn_train_steps = num_epochs * len(train_dataset_loader)\\n# number of validation steps\\nn_valid_steps = len(valid_dataset_loader)\\n# current training step\\ncurrent_step = 0\\n# logging, eval & save steps\\nsave_steps = 1000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# File to log training metrics\n",
    "log_file = open(\"training_logs.txt\", \"w\")\n",
    "\n",
    "# number of training steps\n",
    "n_train_steps = num_epochs * len(train_dataset_loader)\n",
    "# number of validation steps\n",
    "n_valid_steps = len(valid_dataset_loader)\n",
    "# current training step\n",
    "current_step = 0\n",
    "# logging, eval & save steps\n",
    "save_steps = 1000'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a074ab-fbe4-4393-a083-8b933e576930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(rank, world_size, train_dataloader, valid_loader, batch_size=32, num_epochs=10, learning_rate=1e-3, patience=3, weight_decay=1e-5):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=patience)\n",
    "    best_val_loss = float('inf')\n",
    "    stop_counter = 0  # Counter for early stopping\n",
    "\n",
    "    train_losses = []\n",
    "    bleu_values = []\n",
    "    rouge1_values = []\n",
    "    rouge2_values = []\n",
    "    rougeL_values = []\n",
    "    spice_values = []\n",
    "    val_losses = []\n",
    "    prev_lr = optimizer.param_groups[0]['lr']  # Get initial learning rate\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        train_dataloader_iter = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "        for i, data in enumerate(train_dataloader_iter):\n",
    "            pixel_values = batch[\"pixel_values\"].to(rank)\n",
    "            labels = batch[\"labels\"].to(rank)\n",
    "            loss = train_step(model, batch, optimizer, pixel_values, labels)\n",
    "            train_loss += loss\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        if rank == 0:\n",
    "            avg_val_loss, predictions, labels = evaluate_model(model, valid_loader, rank)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "            eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
    "            metrics = compute_metrics(eval_prediction)\n",
    "            \n",
    "            bleu_values.append(metrics['bleu'])\n",
    "            rouge1_values.append(metrics['rouge'])\n",
    "            rouge2_values.append(metrics['rouge2'])\n",
    "            rougeL_values.append(metrics['rougeL'])\n",
    "            spice.append(metrics['spice'])\n",
    "            \n",
    "            print(f\"\\n BLEU: {metrics['bleu']:.4f}, \" +\n",
    "                f\"ROUGE-1: {metrics['rouge1']:.4f}, ROUGE-2: {metrics['rouge2']:.4f}, ROUGE-L: {metrics['rougeL']:.4f},\" +\n",
    "                  f\"SPICE: {metrics['spice']:.4f}\\n\")\n",
    "\n",
    "            scheduler.step(avg_val_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']  # Get current learning rate\n",
    "    \n",
    "            # Print the learning rate only if it changes\n",
    "            if current_lr != prev_lr:\n",
    "                print(\"Learning rate changed to:\", current_lr)\n",
    "                prev_lr = current_lr  # Update previous learning rate\n",
    "    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pt')\n",
    "                checkpoint_path = f\"./image-captioning/checkpoint-{epoch + 1}\"\n",
    "                model.save_pretrained(checkpoint_path)\n",
    "                tokenizer.save_pretrained(checkpoint_path)\n",
    "                image_processor.save_pretrained(checkpoint_path)\n",
    "    \n",
    "                best_val_loss = avg_val_loss\n",
    "                stop_counter = 0\n",
    "            else:\n",
    "                stop_counter += 1\n",
    "    \n",
    "            # Early stopping\n",
    "            if stop_counter >= patience:\n",
    "                print(\"Early stopping...\")\n",
    "                break\n",
    "\n",
    "    print(\"\\n---Finished Training---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94bf2e9d-bdd6-47c5-abaa-cf53936e564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, world_size):\n",
    "    ddp_setup(rank, world_size)\n",
    "\n",
    "    train_loader, valid_loader = get_data_loaders(batch_size, rank, world_size)\n",
    "\n",
    "    # Initialize model\n",
    "    encoder_model = \"microsoft/swin-base-patch4-window7-224-in22k\"\n",
    "    decoder_model = \"gpt2\"\n",
    "    model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder_model, decoder_model).to(rank)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(decoder_model)\n",
    "    image_processor = ViTImageProcessor.from_pretrained(encoder_model)\n",
    "\n",
    "    \n",
    "    if \"gpt2\" in decoder_model:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.eos_token_id = tokenizer.eos_token_id\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "    else:\n",
    "        model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    train_model(rank, world_size, train_loader, valid_loader, batch_size=32, num_epochs=10, learning_rate=1e-3, patience=3, weight_decay=1e-5)\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be32b906-0683-4749-abd3-f116e93d902d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 120, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/nfs/stak/users/arulmozg/hpc-share/miniconda3/envs/genalt/lib/python3.11/multiprocessing/spawn.py\", line 130, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "W0531 12:42:59.158000 22496273216512 torch/multiprocessing/spawn.py:145] Terminating process 3184304 via signal SIGTERM\n",
      "W0531 12:42:59.161000 22496273216512 torch/multiprocessing/spawn.py:145] Terminating process 3184305 via signal SIGTERM\n",
      "W0531 12:42:59.163000 22496273216512 torch/multiprocessing/spawn.py:145] Terminating process 3184307 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 3 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     mp\u001b[38;5;241m.\u001b[39mspawn(train, args\u001b[38;5;241m=\u001b[39m(world_size), nprocs\u001b[38;5;241m=\u001b[39mworld_size, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      3\u001b[0m     world_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:281\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/hpc-share/miniconda3/envs/genalt/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:177\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    171\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    179\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    180\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    181\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    185\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 3 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "# Main function to launch training on all GPUs\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train, args=(world_size), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2035915-f277-4274-ae94-5341c70fe3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model = VisionEncoderDecoderModel.from_pretrained(f\"./image-captioning/checkpoint-{best_checkpoint}\").to(device)\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "metrics = get_evaluation_metrics(best_model, test_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a486be1-6e67-4a27-ac4e-fa95f563afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform inference\n",
    "image_captioner = pipeline(\"image-to-text\", model=\"Abdou/vit-swin-base-224-gpt2-image-captioning\")\n",
    "image_captioner.model = image_captioner.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a446f-ea8e-40ec-a979-400f93e95d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000000001.jpg\")\n",
    "# show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000000019.jpg\")\n",
    "# show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000000128.jpg\")\n",
    "# show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000003072.jpg\")\n",
    "# show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000003324.jpg\")\n",
    "# show_image_and_captions(\"http://images.cocodataset.org/test-stuff2017/000000003720.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef1af9-4e8a-4e46-93ed-2db7c3687b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
